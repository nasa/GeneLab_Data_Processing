############################################################################################
## Configuration file for GeneLab Illumina metagenomics processing workflow               ##
## Developed by Michael D. Lee (Mike.Lee@nasa.gov)                                        ##
############################################################################################

############################################################
##################### VARIABLES TO SET #####################
############################################################

#############################################################
##### These first 5 need to match what is on our system #####
#############################################################

## single-column file with unique portion of sample names
sample_info_file:
    "unique-sample-names.txt"

## raw reads directory (can be relative to workflow directory, or needs to be full path)
raw_reads_dir:
    "../Raw_Data/"

## raw read suffixes (region following the unique part of the sample names)
  # e.g. for "Sample-1_R1_raw.fastq.gz" would be "_R1_raw.fastq.gz"
raw_R1_suffix:
    "_R1_raw.fastq.gz"
raw_R2_suffix:
    "_R2_raw.fastq.gz"

## root directory of reference databases (or where they will be downloaded if they don't exist yet)
    # this should be provided as a full path (starting with `/` as the below example 
    # (note that the the `~/` home shortcut is not expanded
    # by snakemake's evaluation of files, so don't use that)
REF_DB_ROOT_DIR:
    "/path/to/ref-dbs/"

######################################################################
##### The rest only need to be altered if we want to change them #####
######################################################################

## number of threads to use PER snakemake job (which is set with the -j parameter passed to snakemake call)
    # passed to megahit, bowtie2, samtools, metabat2, checkm-pplacer (many may be running concurrently)
num_threads:
    20

## number of CPUs to use PER snakemake job
    # passed to KOFamScan, CAT, checkm (many may be running concurrently)
num_cpus:
    20

## number of CPUs to use for gtdb-tk (only 1 gtdb-tk job will be run, so not multiplied, but the pplacer step can be more memory intensive with more cpus i think)
gtdb_tk_num_cpus:
    20

## maximum memory allowed passed to megahit assembler
    # can be set either by proportion of available on system, e.g. 0.5
    # or by absolute value in bytes, e.g. 100e9 would be 100 GB
max_mem:
    0.5

## MAG filtering cutoffs based on checkm quality assessments (in percent); see https://github.com/Ecogenomics/CheckM/wiki/Reported-Statistics
minimum_estimated_completion:
    90
maximum_estimated_redundancy:
    10
maximum_estimated_strain_heterogeneity:
    0

## quality trimmed/filtered suffixes
trimmed_R1_suffix:
    "_R1_trimmed.fq.gz"
trimmed_R2_suffix:
    "_R2_trimmed.fq.gz"

## output directories (all relative to processing directory, will be created)
fastqc_out_dir:
    "../FastQC_Outputs/"
filtered_reads_dir:
    "../Filtered_Sequence_Data/"
assembly_based_dir:
    "../Assembly-based_Processing/"
assemblies_dir:
    "../Assembly-based_Processing/assemblies/"
genes_dir:
    "../Assembly-based_Processing/predicted-genes/"
annotations_and_tax_dir:
    "../Assembly-based_Processing/annotations-and-taxonomy/"
mapping_dir:
    "../Assembly-based_Processing/read-mapping/"
combined_output_dir:
    "../Assembly-based_Processing/combined-outputs/"
bins_dir:
    "../Assembly-based_Processing/bins/"
MAGs_dir:
    "../Assembly-based_Processing/MAGs/"
read_based_dir:
    "../Read-based_Processing/"
logs_dir:
    "logs/"


#######################################################
################# REFERENCE DATABASES #################
#######################################################
# The below variables probably shouldn't be changed unless we really want to for some reason.
# The workflow will check the location pointed to above for the below databases, and install them
# if they are not already there. It looks for the below "TRIGGER" filenames (they 
# all end with "*_DB_SETUP") in the directory for each database, which it creates when
# it sets them up initially. If we want to point to DBs that already exist on our setup,
# we need to add these (empty) files to their respective directories. The
# workflow just checks the file is there to know it doesn't need to setup the DB.
#
# All together, after installed and unpacked, these will take up about 240 GB. But may 
# require up to 500 GB during installation and initial un-packing. 

## specific database locations
KOFAMSCAN_DIR:
    "kofamscan_db"
KOFAMSCAN_TRIGGER_FILE:
    "KO_DB_SETUP"
CAT_DIR:
    "CAT_prepare_20210107"
CAT_DL_FILE:
    "CAT_prepare_20210107.tar.gz"
CAT_DL_LINK:
    "tbb.bio.uu.nl/bastiaan/CAT_prepare/CAT_prepare_20210107.tar.gz"
CAT_TRIGGER_FILE:
    "CAT_DB_SETUP"
CAT_DB:
    "/2021-01-07_CAT_database"
CAT_TAX:
    "/2021-01-07_taxonomy"
GTDB_DATA_PATH:
    "GTDB-tk-ref-db"
GTDB_TRIGGER_FILE:
    "GTDBTK_DB_SETUP"
HUMANN3_DBS_DIR:
    "humann3-db"
HUMANN3_CHOCOPHLAN_TRIGGER_FILE:
    "CHOCOPHLAN_DB_SETUP"
HUMANN3_UNIREF_TRIGGER_FILE:
    "UNIREF_DB_SETUP"
HUMANN3_UTILITY_MAPPING_TRIGGER_FILE:
    "UTILITY_MAPPING_SETUP"
METAPHLAN3_DB_DIR:
    "metaphlan3-db"
METAPHLAN_TRIGGER_FILE:
    "METAPHLAN3_DB_SETUP"


## example usage command ##
# snakemake --use-conda --conda-prefix ${CONDA_PREFIX}/envs -j 2 -p

# `--use-conda` – this specifies to use the conda environments included in the workflow
# `--conda-prefix` – this allows us to point to where the needed conda environments should be stored. Including this means if we use the workflow on a different dataset somewhere else in the future, it will re-use the same conda environments rather than make new ones. The value listed here, `${CONDA_PREFIX}/envs`, is the default location for conda environments (the variable `${CONDA_PREFIX}` will be expanded to the appropriate location on whichever system it is run on).
# `-j` – this lets us set how many jobs Snakemake should run concurrently (keep in mind that many of the thread and cpu parameters set in the config.yaml file will be multiplied by this)
# `-p` – specifies to print out each command being run to the screen

# See `snakemake -h` for more options and details.
