//******** Global parameters *****************//
params {

    publishDir_mode     = "link" // "copy", "link", "symlink"

    //-------- Parameters used to generate README.txt  ------------------//
    name                = "First M. Last"  // name of analyst
    email               = "NASA@nasa.gov" // email of analyst
    protocol_id         = "GL-DPPD-7104-C"   // Genelab pipeline document protocol id followed
    GLDS_accession      =  null // e.g "GLDS-487"
    OSD_accession       =  null // e.g "OSD-487"
    assay_suffix        =  "_GLAmpSeq"
    readme              = "README${params.assay_suffix}.txt"
    processing_zip_file = "processing_info${params.assay_suffix}.zip"
    /* extra parameters and arguments to GL-gen-processed-amplicon-data-readme command
    run `bin/GL-gen-processed-amplicon-readme --help` for extra parameters that can be set
     "--raw-reads-dir  '../Raw_Sequence_Data/' "
     "--primers-already-trimmed" for Amplicon: if primers were trimmed prior to analysis
     */ 
    readme_extra  =  "" 

    output_prefix = ""
    V_V_guidelines_link = "https://genelab-tools.arc.nasa.gov/confluence/pages/viewpage.action?pageId=2428598"

    // A comma separated list of files to find in processing_info.zip
    target_files             = "bin/,config/,envs/,modules/,main.nf,nextflow.config,unique-sample-IDs.txt"

    // Suffixes
    raw_suffix               = "_raw.fastq.gz"
    raw_R1_suffix            = "_R1_raw.fastq.gz"
    raw_R2_suffix            = "_R2_raw.fastq.gz"
    primer_trimmed_suffix    = "_trimmed.fastq.gz"
    primer_trimmed_R1_suffix = "_R1_trimmed.fastq.gz"
    primer_trimmed_R2_suffix = "_R2_trimmed.fastq.gz"
    filtered_suffix          = "_filtered.fastq.gz"
    filtered_R1_suffix       = "_R1_filtered.fastq.gz"
    filtered_R2_suffix       = "_R2_filtered.fastq.gz"

    /* Extra parameters and arguments to validate-processed-amplicon-data command
    run `bin/GL-validate-processed-amplicon-data --help` for extra parameters that can be set
     "--single-ended" if data are single-ended  
     "--primers-already-trimmed" if primers were trimmed prior to analysis
     "--R1-used-as-single-ended-data" if processing only R1 reads as single-end
     */
     validation_extra = ""

    /* Extra parameters and arguments to GL-gen-file-associations-table command
    run `bin/GL-gen-amplicon-file-associations-table --help` for extra parameters that can be set
     "--single-ended" if data are single-ended  
     "--primers-already-trimmed" for Amplicon: if primers were trimmed prior to analysis
     "--R1-used-as-single-ended-data" if processing only R1 reads as single-end
     */
     file_association_extra = ""

    //------------------------ files ----------------------------//
    main              = "${projectDir}/main.nf"
    nextflow_config   = "${projectDir}/nextflow.config" 
    samples           = "./unique-sample-IDs.txt"
    runsheet          = null // e.g. "../GeneLab/GLfile.csv" or "PE_file.csv"
    software_versions = "../Metadata/software_versions.txt"
    // You only need to supply one of assay_table or isa_zip
    // If you supply both it will use only the assay_table
    assay_table       = null // e.g. "../GeneLab/a_GLDS-487_amplicon-sequencing_16s_illumina-1.txt"
    isa_zip           = null // e.g. "../GeneLab/OSD-487_metadata_GLDS-487-ISA.zip"


    //------------------------- Directories ----------------------//
    // Make sure you always end the directory names with a forward slash "/" and that if you use
    // relative paths, they are located in the run directory (./) or in its parent (../)
    bin                     = "${projectDir}/bin/"
    envs                    = "${projectDir}/envs/"
    modules                 = "${projectDir}/modules/"        
    config_dir              = "${projectDir}/config/"
    Raw_Sequence_Data       = "../Raw_Sequence_Data/"
    FastQC_Outputs          = "../workflow_output/FastQC_Outputs/"
    Trimmed_Sequence_Data   = "../workflow_output/Trimmed_Sequence_Data/"
    Filtered_Sequence_Data  = "../workflow_output/Filtered_Sequence_Data/"
    Final_Outputs           = "../workflow_output/Final_Outputs/"
    Output_dir              = "../Post_Processing/"

    // Specify paths to existing conda environments
    // Leave as is if you'd like to create a new conda environment
    conda_dp_tools = null          // "/path/to/envs/dp_tools"

    debug          = false // set to true if you'd like to see the parameters values printed to the terminal
}

// Used as base for clean file paths
params.baseDir = "${launchDir}"
parent_dir     = "${launchDir.getParent()}"
// Setting the default container engine as singularity
params.containerEngine = "singularity"
// Conda shouldn't be used by default except when using conda-based profiles
params.use_conda = false


/*******************************************************************************************************
*************************************** Workflow Profiles **********************************************
********************************************************************************************************/
profiles {
    slurm {
         process.executor     = 'slurm' 
     }

    conda {   
        conda.enabled          = true
        params.use_conda       = true
        conda.channels         = 'conda-forge,bioconda' 
        conda.cacheDir         = 'conda/' // location of conda environments
        conda.createTimeout    = '2h'              
    }

    mamba {
        conda.enabled          = true
        conda.useMamba         = true
        conda.channels         = 'conda-forge,bioconda'
        params.use_conda       = true
        conda.cacheDir         = 'conda/' // location of conda environments
        conda.createTimeout    = '2h'
    }

    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        singularity.cacheDir   = "singularity/" // local singularity images location
        params.containerEngine = "singularity"
    }

    docker {
        docker.enabled         = true
        docker.runOptions      = '-u $(id -u):$(id -g)'
        params.containerEngine = "docker"
    }
}

// Maximum number of jobs to submit in parallel
executor.queueSize = 20

/************************************************************************************
*********** Tune process specific resources (cpu, container, memory etc.) ***********
*************************************************************************************/
process {
    //******************* Default process settings ************************//
    errorStrategy = "ignore"
    cpus = 2
    memory = '5 GB'
    cache = 'lenient'
    conda = {params.conda_dp_tools ? params.conda_dp_tools : "${projectDir}/envs/dp_tools.yaml"}
    container = "quay.io/nasa_genelab/dp_tools:1.3.6.1"
    publishDir = [path: params.Output_dir, mode: params.publishDir_mode]

    // Mount parent directory for processes that copy files
    withName: "PACKAGE_PROCESSING_INFO|GENERATE_MD5SUMS" {
        containerOptions = {params.containerEngine == "singularity" ? "-B ${parent_dir}" : "-v ${parent_dir}:${parent_dir}"}
    }
}


/******************************************************************************
**************************** Workflow Metadata ********************************
*******************************************************************************/
manifest {
    author = 'Olabiyi Aderemi Obayomi'
    homePage = 'https://github.com/nasa/GeneLab_Data_Processing/blob/master/Amplicon/'
    description = 'Amplicon Illumina post-processing workflow'
    mainScript = 'post_processing.nf'
    defaultBranch = 'main'
    nextflowVersion = '>=24.04.4'
    version = '1.0.0'
}
