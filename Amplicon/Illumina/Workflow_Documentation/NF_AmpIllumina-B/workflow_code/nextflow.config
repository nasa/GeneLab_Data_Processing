//***************************************** Global parameters *******************************************//
params {
    // Mandatory parameters 
    target_region = "16S" // "16S", "18S", "ITS"
    raw_R1_suffix = "_R1_raw.fastq.gz"
    raw_R2_suffix = "_R2_raw.fastq.gz"
    trim_primers  = "TRUE" // "TRUE" or "FALSE"
    

    // -------- Required only if --accession is false ---------------//
    // A 4-column (single-end) or 5-column (paired-end) input csv file with the following headers ( sample_id, forward, [reverse,] paired, groups)
    input_file = null 


    // Cutadapt parameters
    min_cutadapt_len    = 130
    primers_linked      = "TRUE"
    discard_untrimmed   = "TRUE"
    anchored_primers    = "TRUE"
    F_primer            = null
    R_primer            = null

    // Dada2 parameters
    left_trunc     = 0
    right_trunc    = 0
    left_maxEE     = 1
    right_maxEE    = 1
    concatenate_reads_only = "FALSE"

    // If using conda environments specify their locations so new ones won't be created
    conda{
          // Specify the paths to existing conda environments (/path/to/envs/cutadapt)
          // leave as is if you want to create a new conda environment
          cutadapt         = null     // /path/to/envs/cutadapt
          diversity        = null     // /path/to/envs/R_diversity
          dp_tools         = null     // /path/to/envs/dp_tools
          fastqc           = null     // /path/to/envs/fastqc
          multiqc          = null     // /path/to/envs/multiqc
          R                = null     // /path/to/envs/R
          zip              = null     // /path/to/envs/zip
      }


    // Mandatory parameters if using GLDS or OSD accession as input
    accession = null

    assay_suffix   = "_GLAmpSeq"
    output_prefix = ""
    publishDir_mode = "link" // "link", "copy"

    // Suffixes
    primer_trimmed_R1_suffix = "_R1_trimmed.fastq.gz"
    primer_trimmed_R2_suffix = "_R2_trimmed.fastq.gz"
    filtered_R1_suffix       = "_R1_filtered.fastq.gz"
    filtered_R2_suffix       = "_R2_filtered.fastq.gz"


    // Directories
    raw_reads_dir       = "../Raw_Sequence_Data/"
    metadata_dir        = "../Metadata/"
    genelab_dir         = "../GeneLab/"
    fastqc_out_dir      = "../workflow_output/FastQC_Outputs/"
    trimmed_reads_dir   = "../workflow_output/Trimmed_Sequence_Data/"
    filtered_reads_dir  = "../workflow_output/Filtered_Sequence_Data/"
    final_outputs_dir   = "../workflow_output/Final_Outputs/"

    // Multiqc
    multiqc_config = "${projectDir}/config/multiqc.config"

    // -------- Differential abundance parameters ----- //
    diff_abund_method  = "all" // ["all", "ancombc1", "ancombc2", or "deseq2"] - it runs all three by default
    group              = "groups"  // column in input csv file to be compared
    samples_column     = "sample_id" // column in input csv file containing sample names
    remove_struc_zeros = false // should structural zeros be removed when running ANCOMBC?
    // Should rare features and samples be discarded. Values are true or false. If set to true then set the cutoffs below
    remove_rare        = false
    prevalence_cutoff  = 0  // a fraction between 0 and 1 that represents the prevalance in percentage of taxa to be retained
    library_cutoff     = 0 // Samples with library sizes less than this number will be excluded in the analysis
 
    // Minimum desired sample rarefaction depth for diversity analysis
    rarefaction_depth  = 500
 

    errorStrategy  = "terminate"
    debug          = false // set to true if you'd like to see the values of your set parameters
}

// Setting the default container engine as singularity
params.containerEngine = "singularity"
// Conda shouldn't be used by default except when using conda-based profiles
params.use_conda = false


/*******************************************************************************************************
*************************************** Workflow Profiles **********************************************
********************************************************************************************************/

profiles {

    slurm {  
        process.executor       = 'slurm'
    }

    conda {   
        conda.enabled          = true
        params.use_conda       = true
        conda.channels         = 'conda-forge,bioconda' 
        conda.cacheDir         = 'conda/' // location of conda environments
        conda.createTimeout    = '2h'              
    }

    mamba {
        conda.enabled          = true
        conda.useMamba         = true
        conda.channels         = 'conda-forge,bioconda'
        params.use_conda       = true
        conda.cacheDir         = 'conda/' // location of conda environments
        conda.createTimeout    = '2h'
    }

    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        singularity.cacheDir   = "singularity/" // location of singularity images
        params.containerEngine = "singularity"
    }

    docker {
        docker.enabled         = true
        docker.runOptions      = '-u $(id -u):$(id -g)'
        params.containerEngine = "docker"
    }

}

// Maximum number of jobs to submit in parallel
executor.queueSize = 20


/******************************************************************************************************************
***************** Tune process specific resources (cpu, container, memory etc.) ***********************************
*******************************************************************************************************************/

process {

    //******************* Default process settings ************************//
    errorStrategy = { params.errorStrategy ? params.errorStrategy : "ignore" } 
    maxRetries = 2
    cpus = 2
    memory = "5 GB"
    cache = 'lenient'
  //debug = true  // uncomment to see what is being emitted to the standard output

//************************* Accession runsheet and input file retrieval  **************************************//
    withName: GET_RUNSHEET {
                  conda = {params.conda.dp_tools ? params.conda.dp_tools : "envs/dp_tools.yaml"}
                  container = "quay.io/nasa_genelab/dp_tools:1.3.6.1"
                  publishDir = [path: params.genelab_dir, mode: params.publishDir_mode]
            }

//********************************** Read quality control and assesment ********************************************//
    withLabel: fastqc {
                  conda = {params.conda.fastqc ? params.conda.fastqc : "envs/fastqc.yaml"}
                  container = "staphb/fastqc:0.12.1"
            }

    withLabel: zip {
                  conda = {params.conda.zip ? params.conda.zip : "envs/zip.yaml"}
                  container = "quay.io/nasa_genelab/zip:3.0"
           }

    withName: RAW_FASTQC {                  
                  publishDir = [path: params.raw_reads_dir, mode: params.publishDir_mode]
            }

    withName: "RAW_MULTIQC|TRIMMED_MULTIQC" {
                  conda = {params.conda.multiqc ? params.conda.multiqc : "envs/multiqc.yaml"}
                  container = "quay.io/biocontainers/multiqc:1.27.1--pyhdfd78af_0"
            }

    withName: "ZIP_MULTIQC_RAW|ZIP_MULTIQC_TRIMMED" {
                  publishDir = [path: params.fastqc_out_dir, mode: params.publishDir_mode]
            }

    withName: "CUTADAPT|COMBINE_CUTADAPT_LOGS_AND_SUMMARIZE" {
                  conda = {params.conda.cutadapt ?  params.conda.cutadapt : "envs/cutadapt.yaml"}
                  container = "quay.io/biocontainers/cutadapt:5.0--py39hbcbf7aa_0"
                  memory = "10 GB"
                  publishDir = [path: params.trimmed_reads_dir, mode: params.publishDir_mode]
            }
           
    withName: TRIMMED_FASTQC {
                  publishDir = [path: params.filtered_reads_dir, mode: params.publishDir_mode ]
            } 

//********************************** ASV table creation ********************************************//
    withName: "RUN_R_TRIM|RUN_R_NOTRIM" {
                  conda = {params.conda.R ?  params.conda.R : "envs/R.yaml"}
                  container = "quay.io/nasa_genelab/r-dada-decipher-biomformat:1.1"
                  memory = "20 GB"
                  cpus = 10 
                  publishDir = [[path: params.filtered_reads_dir, pattern: "Filtered_Sequence_Data/*",
                                mode: params.publishDir_mode, saveAs: { fn -> fn.substring(fn.lastIndexOf('/')+1) } ],
                                [path: params.final_outputs_dir , pattern: "final_outputs/*.{tsv,biom,fasta}",
                                mode: params.publishDir_mode, saveAs: { fn -> fn.substring(fn.lastIndexOf('/')+1)} ]] 
          }

    withName: ZIP_BIOM {
                  publishDir = [path: "${params.final_outputs_dir}${params.output_prefix}", mode: params.publishDir_mode]
            }

//********************************** Diversity and differential abundance testing ********************************************//
    withLabel: visualization {
                  conda = {params.conda.diversity ? params.conda.diversity : "envs/diversity.yaml"}
                  container = "quay.io/nasa_genelab/r-diversity:1.1"
                  cpus = 5
                  memory = "10 GB"
                  publishDir = [path: "${params.final_outputs_dir}${params.output_prefix}", mode: params.publishDir_mode]
           }

    withName: SOFTWARE_VERSIONS {
                  publishDir = [path: params.metadata_dir, mode: params.publishDir_mode]
            }

}


/*****************************************************************************
********************** Workflow Resource Usage Capturing *********************
******************************************************************************/

// Adapted from : https://github.com/nf-core/rnaseq/blob/master/nextflow.config
def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "../Resource_Usage/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "../Resource_Usage/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "../Resource_Usage/execution_trace_${trace_timestamp}.txt"
}



/******************************************************************************
**************************** Workflow Metadata ********************************
*******************************************************************************/

manifest {
    author = 'Olabiyi Aderemi Obayomi, Mike D. Lee'
    homePage = 'https://github.com/nasa/GeneLab_Data_Processing/blob/master/Amplicon/'
    description = 'Amplicon Illumina workflow for pipeline document GL-DPPD-7104-B'
    mainScript = 'main.nf'
    defaultBranch = 'main'
    nextflowVersion = '>=24.04.4'
    version = '1.0.0'
}
